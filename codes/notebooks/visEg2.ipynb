{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nets import ssd_vgg_300, ssd_common, np_methods\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow session: grow memory when needed. TF, DO NOT USE ALL MY GPU MEMORY!!!\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "isess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SSD 300 Model\n",
    "\n",
    "The SSD 300 network takes 300x300 image inputs. In order to feed any image, the latter is resize to this input shape (i.e.`Resize.WARP_RESIZE`). Note that even though it may change the ratio width / height, the SSD model performs well on resized images (and it is the default behaviour in the original Caffe implementation).\n",
    "\n",
    "SSD anchors correspond to the default bounding boxes encoded in the network. The SSD net output provides offset on the coordinates and dimensions of these anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../checkpoints/ssd_300_vgg.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (300, 300)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Define the SSD model.\n",
    "reuse = True if 'ssd_net' in locals() else None\n",
    "ssd_net = ssd_vgg_300.SSDNet()\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n",
    "\n",
    "# Restore SSD model.\n",
    "ckpt_filename = '../checkpoints/ssd_300_vgg.ckpt'\n",
    "# ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)\n",
    "\n",
    "# SSD default anchor boxes.\n",
    "ssd_anchors = ssd_net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Post-processing pipeline\n",
    "\n",
    "The SSD outputs need to be post-processed to provide proper detections. Namely, we follow these common steps:\n",
    "\n",
    "* Select boxes above a classification threshold;\n",
    "* Clip boxes to the image shape;\n",
    "* Apply the Non-Maximum-Selection algorithm: fuse together boxes whose Jaccard score > threshold;\n",
    "* If necessary, resize bounding boxes to original image shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main image processing routine.\n",
    "import pickle\n",
    "def process_image(img, select_threshold=0.5, nms_threshold=.45, net_shape=(300, 300)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    \n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, ssd_anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    with open('objs.pkl', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([rclasses,rscores,rbboxes], f)\n",
    "    return rclasses, rscores, rbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([18,  9]), array([ 0.88927776,  0.52018094], dtype=float32), array([[ 0.48663515,  0.66947961,  0.94241518,  0.98651397],\n",
      "       [ 0.27246457,  0.        ,  0.94371337,  0.13969558]], dtype=float32))\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "# Test on some demo image and visualize output.\n",
    "import visualization\n",
    "def bboxes_draw_on_img(img, classes, scores, bboxes, colors, thickness=2):\n",
    "    shape = img.shape\n",
    "    print('saving')\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        \n",
    "        #if ind == i:\n",
    "            bbox = bboxes[i]\n",
    "            color = colors[classes[i]]\n",
    "            # Draw bounding box...\n",
    "            p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "            p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "            cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "            crim = img[p1[::-1][1]:p2[::-1][1],p1[::-1][0]:p2[::-1][0]]\n",
    "            cv2.imwrite('crop'+str(i)+'.jpg',crim)\n",
    "            # Draw text...\n",
    "            s = '%s/%.3f' % (classes[i], scores[i])\n",
    "            p1 = (p1[0]-5, p1[1])\n",
    "            cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.4, color, 1)\n",
    "    cv2.imwrite('check2.jpg',img)\n",
    "    return img\n",
    "path = '../demo/'\n",
    "image_names = sorted(os.listdir(path))\n",
    "from IPython.display import Image\n",
    "img = mpimg.imread('/home/subha/ReferralExp/ObjectRetreival/natural-language-object-retrieval/datasets/ReferIt/ImageCLEF/images/1139.jpg')\n",
    "Image('/home/subha/ReferralExp/ObjectRetreival/natural-language-object-retrieval/datasets/ReferIt/ImageCLEF/images/7407.jpg')\n",
    "rclasses, rscores, rbboxes =  process_image(img)\n",
    "print(rclasses, rscores, rbboxes)\n",
    "impl = bboxes_draw_on_img(img, rclasses, rscores, rbboxes, visualization.colors_plasma)\n",
    "# impl = cv2.cvtColor(impl, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(impl)\n",
    "# plt.show()\n",
    "# visualization.plt_bboxes(img, rclasses, rscores, rbboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='check2.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#rightmost animal\n",
    "#1871\n",
    "big boat at bottom\n",
    "9538\n",
    "orange boat on the right\n",
    "8352\n",
    "\n",
    "\n",
    "#result1 : person on horse - 15765\n",
    "#result2 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139_1\n",
      "/home/subha/RefExpCVPR2018/penseur/textFeaturescache/text_1139_1.txt\n",
      "(1, 4800)\n",
      "(1, 4800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48663515  0.66947961  0.94241518  0.98651397]\n",
      " [ 0.27246457  0.          0.94371337  0.13969558]]\n",
      "saving\n",
      "(2, 29188)\n"
     ]
    }
   ],
   "source": [
    "#Get the query feature that was already extracted using skip-thought\n",
    "import json\n",
    "import pickle\n",
    "def load_pickle(name):\n",
    "    print(name)\n",
    "    with open(name,\"rb\") as fp:\n",
    "        l=pickle.load(fp)\n",
    "\n",
    "    return l\n",
    "with open('/home/subha/ReferralExp/ObjectRetreival/natural-language-object-retrieval/data/metadata/referit_query_dict.json') as fp:\n",
    "    d = json.load(fp)\n",
    "query =[u'left bed']\n",
    "# print(d)\n",
    "img_id = d.keys()[d.values().index(query)]\n",
    "# img_id = d[query/\n",
    "\n",
    "print(img_id)\n",
    "qF = load_pickle('/home/subha/RefExpCVPR2018/penseur/textFeaturescache/text_'+str(img_id)+'.txt')\n",
    "print(qF.shape)\n",
    "# import os\n",
    "\n",
    "# # import sys\n",
    "# # os.chdir('/home/subha/RefExpCVPR2018/penseur')\n",
    "# # sys.path.insert(0, '/home/subha/RefExpCVPR2018/penseur')\n",
    "# import json\n",
    "# # sys.path.append('/home/subha/RefExpCVPR2018/penseur')\n",
    "# import skipthoughts\n",
    "# import pickle\n",
    "# import penseur\n",
    "# p = penseur.Penseur()\n",
    "# qF = p.get_vector(query)\n",
    "\n",
    "print(qF.shape)\n",
    "\n",
    "#Extract image features\n",
    "import pickle\n",
    "import visualization\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as mpcm\n",
    "imF=[]\n",
    "def bboxes_draw_on_img(img, classes, scores, bboxes, colors, qF):\n",
    "    shape = img.shape\n",
    "    dis = 1000\n",
    "    res_img = img.copy()\n",
    "    print('saving')\n",
    "    thickness=2\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        bbox = bboxes[i]\n",
    "        color = colors[classes[i]]\n",
    "        # Draw bounding box...\n",
    "        coord = np.array([bbox[0],bbox[1],bbox[2],bbox[3]])\n",
    "        p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "        p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "        cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "        crim = img[p1[::-1][1]:p2[::-1][1],p1[::-1][0]:p2[::-1][0]]\n",
    "        cv2.imwrite('crop'+str(i)+'.jpg',crim)\n",
    "        cimg = image.load_img('crop'+str(i)+'.jpg', target_size=(224, 224))\n",
    "        x=image.img_to_array(cimg)\n",
    "        x = np.expand_dims(x,axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features=model.predict(x)\n",
    "        c=imname\n",
    "        c=c+'_fc7.npy'\n",
    "        f=np.load('/home/subha/ReferralExp/ObjectRetreival/natural-language-object-retrieval/data/referit_context_features/'+c)\n",
    "        iF=np.concatenate((features.flatten(),f.flatten()),axis=0)\n",
    "        iF = np.concatenate((iF,np.array(coord)),axis=0)\n",
    "        imF.append(iF)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         correctBox = [p1,p2]\n",
    "        \n",
    "        # Draw text...\n",
    "        s = '%s/%.3f' % (classes[i], scores[i])\n",
    "        p1 = (p1[0]-5, p1[1])\n",
    "        cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.4, color, 1)\n",
    "    cv2.imwrite('check.jpg',img)\n",
    "    return img,imF\n",
    "imname='7407'\n",
    "img = mpimg.imread('/home/subha/ReferralExp/ObjectRetreival/natural-language-object-retrieval/datasets/ReferIt/ImageCLEF/images/1139.jpg')\n",
    "with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
    "    rclasses, rscores, rbboxes = pickle.load(f)\n",
    "# rclasses, rscores, rbboxes =  process_image(img)\n",
    "print(rbboxes)\n",
    "impl,imF= bboxes_draw_on_img(img, rclasses, rscores, rbboxes, visualization.colors_plasma,qF)\n",
    "imF=np.array(imF)\n",
    "print(imF.shape)\n",
    "with open('features.pkl', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([imF,qF], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46277404]]\n",
      "saving 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pickle\n",
    "import visualization\n",
    "import random\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "\n",
    "num_classes = 10\n",
    "textNames=os.listdir('/home/subha/RefExpCVPR2018/penseur/textFeaturescache')\n",
    "imgNames=os.listdir('/home/subha/RefExpCVPR2018/penseur/finalTrain/imgCache')\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def bboxPred(model,qF,imF):\n",
    "#     sz = imF.shape[0]\n",
    "#     qF =np.tile(qF,(sz,1))\n",
    "#     sc=model.predict([imF,qF])\n",
    "#     sc=sc.ravel()\n",
    "#     print(sc)\n",
    "#     print(imF[0],imF[1])\n",
    "    small=100\n",
    "    smallindex=0\n",
    "    for i in range(imF.shape[0]):\n",
    "        temp=np.array([imF[i]])\n",
    "        sc=model.predict([temp,qF])\n",
    "        if sc.ravel<small:\n",
    "            small=sc\n",
    "            smallindex=i\n",
    "            \n",
    "        print(sc)\n",
    "        return smallindex\n",
    "        \n",
    "#     r=sc.argsort()\n",
    "#     print(r,i)\n",
    "\n",
    "\n",
    "with open('features.pkl') as f:  # Python 3: open(..., 'rb')\n",
    "    imF,qF = pickle.load(f)\n",
    "epochs = 30\n",
    "# te1,te2,tey =np.load('te1.npy'),np.load('te2.npy'),np.load('tey.npy')/\n",
    "input_a = Input(shape=(29188,))\n",
    "input_b = Input(shape=(4800,))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "project_a = Input(shape=(29188,))\n",
    "x = Dense(4800,activation ='relu')(project_a)\n",
    "\n",
    "shared_fc = Dense(128)\n",
    "processed_a = shared_fc(x)\n",
    "processed_b = shared_fc(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([ project_a,input_b], [distance])\n",
    "\n",
    "# train\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "model.load_weights(\"/home/subha/RefExpCVPR2018/penseur/finalTrain/modelFinal.h5\")\n",
    "ind=bboxPred(model,qF,imF)\n",
    "# print(ind)\n",
    "def bboxes_draw_on_img(img, classes, scores, bboxes,ind, colors, thickness=2):\n",
    "    shape = img.shape\n",
    "    print('saving',ind)\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        \n",
    "        if ind == i:\n",
    "            bbox = bboxes[i]\n",
    "            color = colors[classes[i]]\n",
    "            # Draw bounding box...\n",
    "            p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "            p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "            cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "            crim = img[p1[::-1][1]:p2[::-1][1],p1[::-1][0]:p2[::-1][0]]\n",
    "            cv2.imwrite('crop'+str(i)+'.jpg',crim)\n",
    "            # Draw text...\n",
    "            s = '%s/%.3f' % (classes[i], scores[i])\n",
    "            p1 = (p1[0]-5, p1[1])\n",
    "            cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.4, color, 1)\n",
    "    cv2.imwrite('resultbbox2.jpg',img)\n",
    "    return img\n",
    "with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
    "    rclasses, rscores, rbboxes = pickle.load(f)\n",
    "img = mpimg.imread('/home/subha/ReferralExp/ObjectRetreival/natural-language-object-retrieval/datasets/ReferIt/ImageCLEF/images/1139.jpg')  \n",
    "impl =bboxes_draw_on_img(img, rclasses, rscores, rbboxes,ind, visualization.colors_plasma)\n",
    "# y_pred = model.predict([te1,te2])\n",
    "# te_acc,recall_1 = compute_accuracy(tey, y_pred)\n",
    "# results=[te_acc,recall_1]\n",
    "# thefile = open('results_train.txt', 'w')\n",
    "# for item in results:\n",
    "#   thefile.write(\"%s\\n\" % item)\n",
    "# print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "# print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n",
    "# print('Recall@5: %0.2f%%'%(recall_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='resultbbox2.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract query features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test to retrieve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python2)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
